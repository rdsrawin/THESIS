{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89aa34dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 110,280 paragraphs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "paragraphs = np.load(\"paragraph_texts.npy\", allow_pickle=True).tolist()\n",
    "print(f\"Loaded {len(paragraphs):,} paragraphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49947dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 110,280 paragraphs from CSV\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, ast\n",
    "\n",
    "df_meta = pd.read_csv(\"xmlAndHTML_data.csv\")\n",
    "df_meta['Para_list'] = df_meta['Para_list'].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notna(x) and x.strip() else [])\n",
    "df_long = df_meta.explode('Para_list', ignore_index=True)\n",
    "paragraphs = df_long['Para_list'].astype(str).tolist()\n",
    "print(f\"Loaded {len(paragraphs):,} paragraphs from CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14be5d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\feb research\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "No sentence-transformers model found with name C:\\Users\\hp/.cache\\torch\\sentence_transformers\\m3rg-iitd_matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at C:\\Users\\hp/.cache\\torch\\sentence_transformers\\m3rg-iitd_matscibert and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"m3rg-iitd/matscibert\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "paragraphs = [str(p) for p in paragraphs]  # make sure theyâ€™re strings\n",
    "# â€¦ then batchâ€‘encode, build index, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f4c275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\hp/.cache\\torch\\sentence_transformers\\m3rg-iitd_matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at C:\\Users\\hp/.cache\\torch\\sentence_transformers\\m3rg-iitd_matscibert and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1724/1724 [4:56:33<00:00, 10.32s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index & texts with MatSciBERT.\n"
     ]
    }
   ],
   "source": [
    "# 1) install once\n",
    "# !pip install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np, faiss, gc\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "MODEL_NAME = \"m3rg-iitd/matscibert\"   # â† swap here\n",
    "BATCH_SIZE = 64                       # depends on GPU/CPU RAM\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# paragraphs comes from your 110â€¯k df_long\n",
    "paragraphs = [str(p) for p in paragraphs]          # ensure strings\n",
    "\n",
    "# ---- reâ€‘encode ----\n",
    "embs = []\n",
    "for i in tqdm(range(0, len(paragraphs), BATCH_SIZE)):\n",
    "    embs.append(\n",
    "        model.encode(\n",
    "            paragraphs[i:i+BATCH_SIZE],\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,   # cosine\n",
    "            show_progress_bar=False\n",
    "        ).astype(\"float32\")\n",
    "    )\n",
    "embeddings = np.vstack(embs); del embs; gc.collect()\n",
    "\n",
    "# ---- rebuild FAISS (dim = 768) ----\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "faiss.write_index(index, \"matscibert_index.faiss\")\n",
    "np.save(\"matscibert_texts.npy\", np.array(paragraphs, dtype=object))\n",
    "print(\"Saved index & texts with MatSciBERT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df7a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does heat accumulation affect temperatures and the resulting microstructure formation?\n",
      "How does crack self-healing vary with annealing Taand ta?\n",
      "CNT film thickness affects resistivity and conductivity of composite materials\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def retrieve_matsci(query, k=5):\n",
    "    q = model.encode([query], normalize_embeddings=True, convert_to_numpy=True).astype(\"float32\")\n",
    "    D, I = index.search(q, k)\n",
    "    paras = np.load(\"matscibert_texts.npy\", allow_pickle=True)\n",
    "    return [(float(D[0][j]), paras[I[0][j]]) for j in range(k)]\n",
    "\n",
    "print(\"\\n\".join(p[:200] for _, p in retrieve_matsci(\n",
    "    \"How does oxygen vacancy concentration influence perovskite conductivity?\", 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208819a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž  Query: How does heat accumulation affect temperatures and the resulting microstructure formation?\n",
      "\n",
      "[1.000] How does heat accumulation affect temperatures and the resulting microstructure formation? â€¦\n",
      "\n",
      "[0.830] What is the effect of reheating and heat accumulation on microsegregation? â€¦\n",
      "\n",
      "[0.814] How does crack self-healing vary with annealing Taand ta? â€¦\n",
      "\n",
      "[0.805] Thermal conductivity increases with an increase in temperature for all modified CNTs â€¦\n",
      "\n",
      "[0.793] What is the primary mechanism of crack self-healing? â€¦\n",
      "\n",
      "\n",
      "ðŸ”Ž  Query: How does crack selfâ€‘healing vary with annealing temperature and time?\n",
      "\n",
      "[0.866] How does crack self-healing vary with annealing Taand ta? â€¦\n",
      "\n",
      "[0.865] Model accurately predicts grain size evolution in graphene-reinforced aluminum composites â€¦\n",
      "\n",
      "[0.854] Cold welding leads to heterogeneous particle size distributions in powder mixtures â€¦\n",
      "\n",
      "[0.853] Convective heat transfer rate between absorber and water (W) â€¦\n",
      "\n",
      "[0.851] highly deformed regions near particleâ€“particle interfaces (Cluster 2), â€¦\n",
      "\n",
      "\n",
      "ðŸ”Ž  Query: How does CNT film thickness affect the resistivity and conductivity of composite materials?\n",
      "\n",
      "[0.886] CNT film thickness affects resistivity and conductivity of composite materials â€¦\n",
      "\n",
      "[0.861] How does heat accumulation affect temperatures and the resulting microstructure formation? â€¦\n",
      "\n",
      "[0.817] Preventing TiC formation is crucial when synthesizing MWCNTs/Ti composites â€¦\n",
      "\n",
      "[0.815] How do the annealing treatments affect the strength, ductility and fracture toughness of NFA-1? â€¦\n",
      "\n",
      "[0.815] thermal conductivity not only depends on the porosity but also the necking between powder particles; â€¦\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- put this in a notebook cell ---\n",
    "questions = [\n",
    "    \"How does heat accumulation affect temperatures and the resulting microstructure formation?\",\n",
    "    \"How does crack selfâ€‘healing vary with annealing temperature and time?\",\n",
    "    \"How does CNT film thickness affect the resistivity and conductivity of composite materials?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    hits = retrieve_matsci(q, k=5)          # k = number of paragraphs you want\n",
    "    print(f\"\\nðŸ”Ž  Query: {q}\\n\")\n",
    "    for score, para in hits:\n",
    "        print(f\"[{score:.3f}] {para[:250]} â€¦\\n\")   # print the first 250â€¯chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c19a2c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pint\n",
      "  Downloading Pint-0.24.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\hp\\desktop\\feb research\\venv\\lib\\site-packages (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\desktop\\feb research\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: platformdirs>=2.1.0 in c:\\users\\hp\\desktop\\feb research\\venv\\lib\\site-packages (from pint) (4.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\hp\\desktop\\feb research\\venv\\lib\\site-packages (from pint) (4.13.2)\n",
      "Collecting flexcache>=0.3 (from pint)\n",
      "  Downloading flexcache-0.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting flexparser>=0.4 (from pint)\n",
      "  Downloading flexparser-0.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\feb research\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading Pint-0.24.4-py3-none-any.whl (302 kB)\n",
      "Downloading flexcache-0.3-py3-none-any.whl (13 kB)\n",
      "Downloading flexparser-0.4-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: flexparser, flexcache, pint\n",
      "\n",
      "   -------------------------- ------------- 2/3 [pint]\n",
      "   -------------------------- ------------- 2/3 [pint]\n",
      "   -------------------------- ------------- 2/3 [pint]\n",
      "   -------------------------- ------------- 2/3 [pint]\n",
      "   -------------------------- ------------- 2/3 [pint]\n",
      "   ---------------------------------------- 3/3 [pint]\n",
      "\n",
      "Successfully installed flexcache-0.3 flexparser-0.4 pint-0.24.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pint regex tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "041bb122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_21600\\102697741.py:6: DeprecationWarning: This function will be removed in future versions of pint.\n",
      "Use ureg.formatter.default_format\n",
      "  ureg.default_format = \"~P\"      # nice compact unit printing\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110280/110280 [00:15<00:00, 7192.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_id value unit_raw unit_normalized\n",
      "0      88     0        K             0 K\n",
      "1      89   300        K           300 K\n",
      "2      92   298        K           298 K\n",
      "3      98     0        K             0 K\n",
      "4      98     0        K             0 K\n",
      "Found 158,096 numberâ€‘unit pairs.\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd, numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from pint import UnitRegistry\n",
    "\n",
    "ureg = UnitRegistry()\n",
    "ureg.default_format = \"~P\"      # nice compact unit printing\n",
    "\n",
    "# 1) Build a pattern for SI symbols + prefixes\n",
    "#    (m, mm, Âµm, kg, kPa, GPa, s, ms, Â°C, K, A, V, Î©, W, J, mol, cdâ€¦)\n",
    "prefix = r\"(?:[fpnumcdkMGT]?)(?:\\s*|Â·|-|Ã—)?\"\n",
    "unit_symbols = (\n",
    "    \"m|g|kg|s|ms|Âµs|A|K|Â°C|mol|cd|Pa|kPa|MPa|GPa|N|J|W|V|Î©|F|H|C|T|lx|Hz\"\n",
    ")\n",
    "pattern = re.compile(\n",
    "    rf\"(?P<value>[+-]?(\\d+(\\.\\d+)?|\\.\\d+)([eE][+-]?\\d+)?)\\s*\"\n",
    "    rf\"(?P<unit>{prefix}(?:{unit_symbols}))\\b\"\n",
    ")\n",
    "\n",
    "records = []\n",
    "for i, (para_id, txt) in tqdm(enumerate(df_long[\"text\"].items()), total=len(df_long)):\n",
    "    for m in pattern.finditer(txt):\n",
    "        val, unit = m.group(\"value\"), m.group(\"unit\")\n",
    "        try:\n",
    "            quantity = (float(val) * ureg(unit)).to_base_units()\n",
    "            norm_unit = f\"{quantity.magnitude:g} {quantity.units}\"\n",
    "        except Exception:\n",
    "            norm_unit = None\n",
    "        records.append({\n",
    "            \"row_id\": para_id,\n",
    "            \"value\": val,\n",
    "            \"unit_raw\": unit,\n",
    "            \"unit_normalized\": norm_unit,\n",
    "        })\n",
    "\n",
    "df_units = pd.DataFrame(records)\n",
    "print(df_units.head())\n",
    "print(f\"Found {len(df_units):,} numberâ€‘unit pairs.\")\n",
    "df_units.to_csv(\"si_units_extracted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a9724a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2d5a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_21600\\2738365103.py:4: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_units = pd.read_csv(\"si_units_extracted.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot saved to units_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Load your extracted-units CSV (adjust path if needed)\n",
    "df_units = pd.read_csv(\"si_units_extracted.csv\")\n",
    "\n",
    "# 2) Convert the â€˜valueâ€™ column to float for aggregation\n",
    "df_units[\"value\"] = df_units[\"value\"].astype(float)\n",
    "\n",
    "# 3) Build a pivot summarizing count, mean, median per unit\n",
    "pivot = df_units.pivot_table(\n",
    "    index=\"unit_raw\",\n",
    "    values=\"value\",\n",
    "    aggfunc=[\"count\", \"mean\", \"median\"]\n",
    ")\n",
    "pivot.columns = [\"count\", \"mean\", \"median\"]\n",
    "pivot = pivot.sort_values(\"count\", ascending=False)\n",
    "\n",
    "# 4) Save to Excel\n",
    "pivot.to_excel(\"units_summary.xlsx\", index=True)\n",
    "\n",
    "print(\"Pivot saved to units_summary.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4a3ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unit_raw                                top_material_titles\n",
      "0       -A  [Nonlocal modeling and analysis of spatiotempo...\n",
      "1       -C  [Copper melt filtration with carbon-bonded alu...\n",
      "2       -F  [Enhancing coatings mechanical performance by ...\n",
      "3       -H  [Functionalized metal oxide particles with ant...\n",
      "4      -Hz  [Improving the high-temperature oxidation resi...\n",
      "5       -J  [Sheet thickness dependence of magnetization p...\n",
      "6       -K  [Oxidation limited thermal boundary conductanc...\n",
      "7       -N  [Dual-phase high-entropy ultra-high temperatur...\n",
      "8       -T  [Electronic, magnetic, optical properties, and...\n",
      "9       -V  [Porous-anodic-alumina-templated Ta-Nb-alloy/o...\n",
      "Saved mappings to unit_to_materials.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_21600\\3693015218.py:18: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_units = pd.read_csv(\"si_units_extracted.csv\")  # row_id, value, unit_raw, ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# 1) Load and explode the metadata table\n",
    "df_meta = pd.read_csv(\"xmlAndHTML_data.csv\")\n",
    "df_meta[\"Para_list\"] = df_meta[\"Para_list\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notna(x) and x.strip() else []\n",
    ")\n",
    "df_long = (\n",
    "    df_meta[[\"DOI\", \"Title\", \"Para_list\"]]\n",
    "    .explode(\"Para_list\", ignore_index=True)\n",
    "    .rename(columns={\"Para_list\": \"text\"})\n",
    ")\n",
    "\n",
    "# now df_long has DOI, Title, text\n",
    "\n",
    "# 2) Load your SI-unit extractions\n",
    "df_units = pd.read_csv(\"si_units_extracted.csv\")  # row_id, value, unit_raw, ...\n",
    "\n",
    "# 3) Ensure row_id lines up\n",
    "df_long = df_long.reset_index().rename(columns={\"index\": \"row_id\"})\n",
    "\n",
    "# 4) Merge units back to metadata\n",
    "df_merged = df_units.merge(\n",
    "    df_long[[\"row_id\", \"DOI\", \"Title\"]],\n",
    "    on=\"row_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 5) For each unit, list the top 5 most frequent paper titles\n",
    "unit_to_titles = (\n",
    "    df_merged\n",
    "      .groupby(\"unit_raw\")[\"Title\"]\n",
    "      .apply(lambda ts: ts.value_counts().head(5).index.tolist())\n",
    "      .reset_index(name=\"top_material_titles\")\n",
    ")\n",
    "\n",
    "# 6) Inspect and save\n",
    "print(unit_to_titles.head(10))\n",
    "unit_to_titles.to_csv(\"unit_to_materials.csv\", index=False)\n",
    "print(\"Saved mappings to unit_to_materials.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc7813aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_units = {\n",
    "    \"m\", \"g\", \"kg\", \"s\", \"A\", \"K\", \"mol\", \"cd\",\n",
    "    \"Hz\", \"N\", \"Pa\", \"J\", \"W\", \"C\", \"V\", \"F\", \"Î©\", \"T\",\n",
    "    \"Â°C\", \"lx\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "801472ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_merged[df_merged[\"unit_raw\"].isin(valid_units)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a6331de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit_raw                                top_material_titles\n",
      "0         A  [An analysis of microstructural morphology, su...\n",
      "1         C  [Interface and mechanical/thermal properties o...\n",
      "2         F  [Repeatability and reproducibility of liquid-p...\n",
      "3        Hz  [Poly(amide-triazole)s obtained by regioselect...\n",
      "4         J  [Developing thermoplastic hybrid titanium comp...\n",
      "5         K  [New insights into thermal processes of metal ...\n",
      "6         N  [A first-principles study of the effects of at...\n",
      "7        Pa  [Novel class of nanostructured metallic glass ...\n",
      "8         T  [1T MoS2 nanosheets with extraordinary sodium ...\n",
      "9         V  [Findings and perspectives of Î²-Ti alloys with...\n",
      "10        W  [Resolving the porosity-unmelted inclusion dil...\n",
      "11       cd  [Physical characterization of Ag:WO3 cermet fi...\n",
      "12        g  [Metal Nanoparticle Harvesting by Continuous R...\n",
      "13       kg  [Thermal conductivity of different materials n...\n",
      "14        m  [On new solvatomorphs of the metalloligand [Ni...\n",
      "15      mol  [Phase behavior and electrochemical properties...\n",
      "16        s  [Effect of vanadium thickness and deposition t...\n",
      "17       Â°C  [Optimization of silver-containing bioglass na...\n",
      "18        Î©  [Comparison of the resistivities of nanostruct...\n"
     ]
    }
   ],
   "source": [
    "unit_to_titles_clean = (\n",
    "    df_filtered\n",
    "      .groupby(\"unit_raw\")[\"Title\"]\n",
    "      .apply(lambda ts: ts.value_counts().head(5).index.tolist())\n",
    "      .reset_index(name=\"top_material_titles\")\n",
    ")\n",
    "\n",
    "print(unit_to_titles_clean)\n",
    "unit_to_titles_clean.to_csv(\"unit_to_materials_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1f1dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_property(text, val, unit):\n",
    "    # cast to strings\n",
    "    val_str, unit_str = str(val), str(unit)\n",
    "    # look for up to 5 words immediately before the value+unit\n",
    "    # we use a non-capture group and word boundaries\n",
    "    pattern = (\n",
    "        r\"(?:\\b\\w+\\b[\\s,.:;â€“-]?){0,5}\"  # up to 5 words or numbers + optional separator\n",
    "        + re.escape(val_str)\n",
    "        + r\"\\s*\"\n",
    "        + re.escape(unit_str)\n",
    "    )\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        snippet = match.group(0)\n",
    "        # return only the words before the number\n",
    "        # split on the value so we only keep the left side\n",
    "        return snippet.split(val_str)[0].strip()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8318284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       top_property_phrases  \\\n",
      "unit_raw                                                      \n",
      "-A               [, 8k-A, fluctuations are stable when8k-A]   \n",
      "-C                                        [, KIC-2, N00014]   \n",
      "-F        [, MMC coatings with a Colmonoy, previously ob...   \n",
      "-H                   [, and single layer graphene on, FZ-T]   \n",
      "-Hz             [with 30-Î¼s pulses and, were provided by a]   \n",
      "...                                                     ...   \n",
      "Ã—K                                                       []   \n",
      "Ã—T                                                       []   \n",
      "Ã—V                                                       []   \n",
      "Ã—g        [and precipitated by centrifugation at, , the ...   \n",
      "Î©                                               [, and, to]   \n",
      "\n",
      "                                        top_material_titles  \n",
      "unit_raw                                                     \n",
      "-A        [Nonlocal modeling and analysis of spatiotempo...  \n",
      "-C        [Copper melt filtration with carbon-bonded alu...  \n",
      "-F        [Enhancing coatings mechanical performance by ...  \n",
      "-H        [Functionalized metal oxide particles with ant...  \n",
      "-Hz       [Improving the high-temperature oxidation resi...  \n",
      "...                                                     ...  \n",
      "Ã—K        [Single-phase duodenary high-entropy fluorite/...  \n",
      "Ã—T        [High temperature elastic properties of sub-st...  \n",
      "Ã—V        [Additive manufacturing of 17â€“4 PH steel using...  \n",
      "Ã—g        [Engineering exosome membrane disguised therma...  \n",
      "Î©         [Comparison of the resistivities of nanostruct...  \n",
      "\n",
      "[198 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# After merging df_units with df_long â€¦\n",
    "df_units[\"prop_phrase\"] = df_units.apply(\n",
    "    lambda r: extract_property(r[\"text\"], r[\"value\"], r[\"unit_raw\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Then group by unit\n",
    "grouped = df_units.groupby(\"unit_raw\").agg({\n",
    "    \"prop_phrase\": lambda ps: pd.Series(ps.dropna()).value_counts().head(3).index.tolist(),\n",
    "    \"Title\":       lambda ts: pd.Series(ts).value_counts().head(3).index.tolist()\n",
    "}).rename(columns={\n",
    "    \"prop_phrase\":\"top_property_phrases\",\n",
    "    \"Title\":\"top_material_titles\"\n",
    "})\n",
    "\n",
    "print(grouped)\n",
    "grouped.to_csv(\"unit_properties_and_materials.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4f1e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_21600\\621462014.py:32: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_units = pd.read_csv(\"si_units_extracted.csv\")      # row_id, value, unit_raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! See unit_properties_and_materials_electronics.csv for the full mapping.\n",
      "   unit_raw                               top_property_phrases  \\\n",
      "0         A                                    [, and, Figure]   \n",
      "1         C                                [, Figure, Figures]   \n",
      "2         F                                    [, JSM, Figure]   \n",
      "3        GA                                                 []   \n",
      "4        GC                                                 []   \n",
      "..      ...                                                ...   \n",
      "65       nV                                                 []   \n",
      "66       nW         [, starting from 30,, to a power level of]   \n",
      "67       nÎ©  [, copper resistivity down to about, showed a ...   \n",
      "68       Â°C                                    [, C and, C to]   \n",
      "69        Î©                                        [, and, to]   \n",
      "\n",
      "                                  top_material_titles  \n",
      "0   [An analysis of microstructural morphology, su...  \n",
      "1   [Interface and mechanical/thermal properties o...  \n",
      "2   [Repeatability and reproducibility of liquid-p...  \n",
      "3   [Polymer actuator based on PVA/PAMPS ionic mem...  \n",
      "4   [Enhancing the optical performance of oxyfluor...  \n",
      "..                                                ...  \n",
      "65  [Superconducting properties of the pyrochlore ...  \n",
      "66  [Tailoring the selectivity of ultralow-power h...  \n",
      "67  [Direct 3D microprinting of highly conductive ...  \n",
      "68  [Optimization of silver-containing bioglass na...  \n",
      "69  [Comparison of the resistivities of nanostruct...  \n",
      "\n",
      "[70 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, re, ast\n",
    "\n",
    "# 1) Define prefixes and an expanded set of base units\n",
    "prefixes   = [\"\", \"k\", \"M\", \"G\", \"m\", \"Âµ\", \"n\"]  # kilo, Mega, Giga, milli, micro, nano\n",
    "\n",
    "# Base units covering thermal, mechanical, electrical, electronics, magnetic, etc.\n",
    "base_units = {\n",
    "    # Temperature\n",
    "    \"K\", \"Â°C\",\n",
    "    # Mechanics (stress, modulus)\n",
    "    \"Pa\", \"N\",\n",
    "    # Electro-magnetic\n",
    "    \"V\", \"A\", \"Î©\", \"Hz\", \"F\", \"S\", \"H\",  # Henry for inductance, Siemens for conductance\n",
    "    # Derived electrical per-length or per-area\n",
    "    \"S/m\", \"Î©Â·m\", \"F/m\", \n",
    "    # Energy / power\n",
    "    \"J\", \"W\",\n",
    "    # Magnetic flux density\n",
    "    \"T\",\n",
    "    # Charge\n",
    "    \"C\",\n",
    "}\n",
    "\n",
    "# Build whitelist of all prefixed variants\n",
    "valid_units = {\n",
    "    f\"{p}{u}\"\n",
    "    for p in prefixes\n",
    "    for u in base_units\n",
    "}\n",
    "\n",
    "# 2) Reload the unit-extraction and metadata\n",
    "df_units = pd.read_csv(\"si_units_extracted.csv\")      # row_id, value, unit_raw\n",
    "df_meta  = pd.read_csv(\"xmlAndHTML_data.csv\")         # DOI, Title, Para_list\n",
    "\n",
    "# 3) Explode metadata to get row_id â†’ text, DOI, Title\n",
    "df_meta[\"Para_list\"] = df_meta[\"Para_list\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notna(x) and x.strip() else []\n",
    ")\n",
    "df_long = (\n",
    "    df_meta[[\"DOI\",\"Title\",\"Para_list\"]]\n",
    "    .explode(\"Para_list\", ignore_index=True)\n",
    "    .rename(columns={\"Para_list\":\"text\"})\n",
    ").reset_index().rename(columns={\"index\":\"row_id\"})\n",
    "\n",
    "# 4) Merge and filter to only our valid units\n",
    "df = (\n",
    "    df_units\n",
    "      .merge(df_long[[\"row_id\",\"Title\",\"text\"]], on=\"row_id\", how=\"left\")\n",
    "      .loc[lambda d: d[\"unit_raw\"].isin(valid_units)]\n",
    ")\n",
    "\n",
    "# 5) Helper to grab the few words before each occurrence\n",
    "def extract_prop(text, val, unit):\n",
    "    val, unit = str(val), str(unit)\n",
    "    pat = (\n",
    "        r\"(?:\\b\\w+\\b[\\s,.:;â€“-]?){0,5}\"\n",
    "        + re.escape(val)\n",
    "        + r\"\\s*\"\n",
    "        + re.escape(unit)\n",
    "    )\n",
    "    m = re.search(pat, text)\n",
    "    if not m:\n",
    "        return None\n",
    "    snippet = m.group(0)\n",
    "    return snippet.split(val)[0].strip()\n",
    "\n",
    "df[\"prop_phrase\"] = df.apply(\n",
    "    lambda r: extract_prop(r[\"text\"], r[\"value\"], r[\"unit_raw\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 6) Aggregate top-3 property phrases & material titles per unit\n",
    "result = df.groupby(\"unit_raw\").agg({\n",
    "    \"prop_phrase\": lambda ps: pd.Series(ps.dropna())\n",
    "                                   .value_counts()\n",
    "                                   .head(3)\n",
    "                                   .index\n",
    "                                   .tolist(),\n",
    "    \"Title\":       lambda ts: pd.Series(ts)\n",
    "                                   .value_counts()\n",
    "                                   .head(3)\n",
    "                                   .index\n",
    "                                   .tolist()\n",
    "}).rename(columns={\n",
    "    \"prop_phrase\":\"top_property_phrases\",\n",
    "    \"Title\":\"top_material_titles\"\n",
    "}).reset_index()\n",
    "\n",
    "# 7) Save and display\n",
    "result.to_csv(\"unit_properties_and_materials_electronics.csv\", index=False)\n",
    "print(\"Done! See unit_properties_and_materials_electronics.csv for the full mapping.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "909c1759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_21600\\1822363212.py:15: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_units = pd.read_csv(\"si_units_extracted.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit_raw  occurrences  paragraph_count  \\\n",
      "0         A         6988             3901   \n",
      "1         C         3309             1825   \n",
      "2         F         1031              755   \n",
      "3        GA            1                1   \n",
      "4        GC           17               11   \n",
      "..      ...          ...              ...   \n",
      "65       nV            1                1   \n",
      "66       nW           16                9   \n",
      "67       nÎ©           12                9   \n",
      "68       Â°C        36458            15214   \n",
      "69        Î©         1046              560   \n",
      "\n",
      "                                 top_property_phrases  \\\n",
      "0                                     [, and, Figure]   \n",
      "1                                 [, Figure, Figures]   \n",
      "2                                     [, JSM, Figure]   \n",
      "3                                                  []   \n",
      "4                                                  []   \n",
      "..                                                ...   \n",
      "65                                                 []   \n",
      "66         [, starting from 30,, to a power level of]   \n",
      "67  [, copper resistivity down to about, showed a ...   \n",
      "68                                    [, C and, C to]   \n",
      "69                                        [, and, to]   \n",
      "\n",
      "                                  top_material_titles  \n",
      "0   [An analysis of microstructural morphology, su...  \n",
      "1   [Interface and mechanical/thermal properties o...  \n",
      "2   [Repeatability and reproducibility of liquid-p...  \n",
      "3   [Polymer actuator based on PVA/PAMPS ionic mem...  \n",
      "4   [Enhancing the optical performance of oxyfluor...  \n",
      "..                                                ...  \n",
      "65  [Superconducting properties of the pyrochlore ...  \n",
      "66  [Tailoring the selectivity of ultralow-power h...  \n",
      "67  [Direct 3D microprinting of highly conductive ...  \n",
      "68  [Optimization of silver-containing bioglass na...  \n",
      "69  [Comparison of the resistivities of nanostruct...  \n",
      "\n",
      "[70 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, re, ast\n",
    "\n",
    "# 1) Reload & explode metadata\n",
    "df_meta = pd.read_csv(\"xmlAndHTML_data.csv\")\n",
    "df_meta[\"Para_list\"] = df_meta[\"Para_list\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notna(x) and x.strip() else []\n",
    ")\n",
    "df_long = (\n",
    "    df_meta[[\"DOI\",\"Title\",\"Para_list\"]]\n",
    "    .explode(\"Para_list\", ignore_index=True)\n",
    "    .rename(columns={\"Para_list\":\"text\"})\n",
    ").reset_index().rename(columns={\"index\":\"row_id\"})\n",
    "\n",
    "# 2) Load extractions & merge\n",
    "df_units = pd.read_csv(\"si_units_extracted.csv\")\n",
    "df = df_units.merge(\n",
    "    df_long[[\"row_id\",\"Title\",\"text\"]], on=\"row_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# 3) Whitelist (as before)\n",
    "prefixes   = [\"\", \"k\", \"M\", \"G\", \"m\", \"Âµ\", \"n\"]\n",
    "base_units = {\"K\",\"Â°C\",\"Pa\",\"N\",\"V\",\"A\",\"Î©\",\"Hz\",\"F\",\"S\",\"H\",\"S/m\",\"Î©Â·m\",\"F/m\",\"J\",\"W\",\"T\",\"C\"}\n",
    "valid_units = {f\"{p}{u}\" for p in prefixes for u in base_units}\n",
    "df = df[df[\"unit_raw\"].isin(valid_units)]\n",
    "\n",
    "# 4) Extract the property phrase (optional, reuse your extract_prop)\n",
    "def extract_prop(text, val, unit):\n",
    "    val, unit = str(val), str(unit)\n",
    "    pat = (r\"(?:\\b\\w+\\b[\\s,.:;â€“-]?){0,5}\"\n",
    "           + re.escape(val) + r\"\\s*\" + re.escape(unit))\n",
    "    m = re.search(pat, text)\n",
    "    return m.group(0).split(val)[0].strip() if m else None\n",
    "\n",
    "df[\"prop_phrase\"] = df.apply(\n",
    "    lambda r: extract_prop(r[\"text\"], r[\"value\"], r[\"unit_raw\"]), axis=1\n",
    ")\n",
    "\n",
    "# 5) Aggregate per unit\n",
    "agg = df.groupby(\"unit_raw\").agg(\n",
    "    occurrences       = (\"unit_raw\",     \"size\"),                # total matches\n",
    "    paragraph_count   = (\"row_id\",       lambda s: s.nunique()),  # distinct paragraphs\n",
    "    top_property_phrases = (\"prop_phrase\", lambda ps: pd.Series(ps.dropna())\n",
    "                                              .value_counts()\n",
    "                                              .head(3)\n",
    "                                              .index\n",
    "                                              .tolist()),\n",
    "    top_material_titles   = (\"Title\",       lambda ts: pd.Series(ts)\n",
    "                                              .value_counts()\n",
    "                                              .head(3)\n",
    "                                              .index\n",
    "                                              .tolist())\n",
    ").reset_index()\n",
    "\n",
    "# 6) Save & inspect\n",
    "agg.to_csv(\"unit_summary_with_counts.csv\", index=False)\n",
    "print(agg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
